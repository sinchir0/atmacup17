{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "debertaでの学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:30.680354Z",
     "iopub.status.busy": "2024-08-30T03:24:30.679868Z",
     "iopub.status.idle": "2024-08-30T03:24:30.689953Z",
     "shell.execute_reply": "2024-08-30T03:24:30.689284Z"
    }
   },
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e010-predict-rating-lrg-fold1\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-large\"\n",
    "COMPETITION_NAME = \"atmacup17\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "ENV_PATH = \"env_file\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "# TARGET_COL = \"Recommended IND\"\n",
    "TARGET_COL = \"Rating\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "# UPLOAD_DATA_TO_KAGGLE = True\n",
    "WANDB = True\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 512\n",
    "INFERENCE_MAX_LENGTH = 512\n",
    "SEED = 42\n",
    "EPOCH = 5\n",
    "LR = 2e-05\n",
    "TRAIN_BS = 8\n",
    "GRAD_ACC_STEP = 128 // TRAIN_BS  # 仮想的なバッチサイズはTRAIN_BS * GRAD_ACC_STEPとなる\n",
    "EVAL_BS = 8\n",
    "NUM_LABELS = 1  # 2\n",
    "\n",
    "USE_FOLD = 1  # Fold数は3(0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:30.692946Z",
     "iopub.status.busy": "2024-08-30T03:24:30.692520Z",
     "iopub.status.idle": "2024-08-30T03:24:31.644651Z",
     "shell.execute_reply": "2024-08-30T03:24:31.643733Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:31.648871Z",
     "iopub.status.busy": "2024-08-30T03:24:31.648158Z",
     "iopub.status.idle": "2024-08-30T03:24:32.530842Z",
     "shell.execute_reply": "2024-08-30T03:24:32.529372Z"
    }
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:32.534583Z",
     "iopub.status.busy": "2024-08-30T03:24:32.534291Z",
     "iopub.status.idle": "2024-08-30T03:24:32.541911Z",
     "shell.execute_reply": "2024-08-30T03:24:32.540984Z"
    }
   },
   "outputs": [],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return \"kernel\", f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return \"nohup\", f\"../../{base_path}\"\n",
    "    elif cwd == f\"/content\":\n",
    "        print(\"Google Colab!\")\n",
    "        return \"colab\", f\"/content/drive/MyDrive/Kaggle/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd.startswith(\"/home/shinichiro.saito\"):\n",
    "        print(\"GCP!\")\n",
    "        return \"GCP\", f\"/home/shinichiro.saito/{COMPETITION_NAME}/{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "ENV_NAME, DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "_, MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)\n",
    "_, ENV_PATH = resolve_path(ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:32.544746Z",
     "iopub.status.busy": "2024-08-30T03:24:32.544490Z",
     "iopub.status.idle": "2024-08-30T03:24:32.549410Z",
     "shell.execute_reply": "2024-08-30T03:24:32.548494Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:32.552236Z",
     "iopub.status.busy": "2024-08-30T03:24:32.551968Z",
     "iopub.status.idle": "2024-08-30T03:24:32.571376Z",
     "shell.execute_reply": "2024-08-30T03:24:32.570535Z"
    }
   },
   "outputs": [],
   "source": [
    "if ENV_NAME != \"GCP\":\n",
    "    %pip install -qq polars==1.0.0\n",
    "    %pip install -qq transformers==4.42.3\n",
    "    %pip install -qq sentencepiece==0.2.0\n",
    "    %pip install -qq datasets==2.20.0\n",
    "    %pip install -qq evaluate==0.4.2\n",
    "    %pip install -qq seqeval==1.2.2\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq python-dotenv==1.0.1\n",
    "    %pip install -qq wandb==0.17.4\n",
    "    %pip install -qq bitsandbytes==0.43.1\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq peft==0.11.1\n",
    "\n",
    "    # formatter\n",
    "    %pip install -qq black isort\n",
    "\n",
    "    %pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:32.574109Z",
     "iopub.status.busy": "2024-08-30T03:24:32.573845Z",
     "iopub.status.idle": "2024-08-30T03:24:37.377581Z",
     "shell.execute_reply": "2024-08-30T03:24:37.376453Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import wandb\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Value,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    ClassLabel,\n",
    ")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    DebertaV2PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
    "    ContextPooler,\n",
    "    StableDropout,\n",
    "    DebertaV2Model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:37.381566Z",
     "iopub.status.busy": "2024-08-30T03:24:37.381032Z",
     "iopub.status.idle": "2024-08-30T03:24:37.389695Z",
     "shell.execute_reply": "2024-08-30T03:24:37.388603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()\n",
    "NUM_PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:37.427009Z",
     "iopub.status.busy": "2024-08-30T03:24:37.426480Z",
     "iopub.status.idle": "2024-08-30T03:24:37.475123Z",
     "shell.execute_reply": "2024-08-30T03:24:37.474148Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.42.3\"\n",
    "assert datasets.__version__ == \"2.20.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:37.478419Z",
     "iopub.status.busy": "2024-08-30T03:24:37.478042Z",
     "iopub.status.idle": "2024-08-30T03:24:37.483959Z",
     "shell.execute_reply": "2024-08-30T03:24:37.483113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:37.487323Z",
     "iopub.status.busy": "2024-08-30T03:24:37.486609Z",
     "iopub.status.idle": "2024-08-30T03:24:37.496392Z",
     "shell.execute_reply": "2024-08-30T03:24:37.495494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{ENV_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:37.499350Z",
     "iopub.status.busy": "2024-08-30T03:24:37.499102Z",
     "iopub.status.idle": "2024-08-30T03:24:47.533001Z",
     "shell.execute_reply": "2024-08-30T03:24:47.532141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:47.536527Z",
     "iopub.status.busy": "2024-08-30T03:24:47.536026Z",
     "iopub.status.idle": "2024-08-30T03:24:47.542430Z",
     "shell.execute_reply": "2024-08-30T03:24:47.541797Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/rec_stratified_fold.json\") as f:\n",
    "    label_stratified_fold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:47.545497Z",
     "iopub.status.busy": "2024-08-30T03:24:47.544902Z",
     "iopub.status.idle": "2024-08-30T03:24:47.585693Z",
     "shell.execute_reply": "2024-08-30T03:24:47.584676Z"
    }
   },
   "outputs": [],
   "source": [
    "train = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train_with_index.csv\")\n",
    "    .join(pl.read_csv(f\"{DATA_PATH}/clothing_master.csv\"), on=\"Clothing ID\", how=\"left\")\n",
    "    .with_columns(\n",
    "        pl.col(\"Title\").fill_null(\"\"),\n",
    "        pl.col(\"Review Text\").fill_null(\"\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(TARGET_COL).cast(pl.Float32),\n",
    "    )\n",
    "    .with_columns(pl.col(TARGET_COL) - 1)  # 0始まりにする\n",
    "    .rename({TARGET_COL: \"label\"})\n",
    "    .with_columns(  # foldを追加する\n",
    "        pl.col(\"index\").replace(label_stratified_fold).alias(\"fold\")\n",
    "    )\n",
    ")\n",
    "\n",
    "test = pl.read_csv(f\"{DATA_PATH}/test.csv\").with_columns(\n",
    "    pl.col(\"Title\").fill_null(\"\"),\n",
    "    pl.col(\"Review Text\").fill_null(\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:47.589363Z",
     "iopub.status.busy": "2024-08-30T03:24:47.588726Z",
     "iopub.status.idle": "2024-08-30T03:24:47.593105Z",
     "shell.execute_reply": "2024-08-30T03:24:47.592016Z"
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.head(100)\n",
    "    test = test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:47.596116Z",
     "iopub.status.busy": "2024-08-30T03:24:47.595608Z",
     "iopub.status.idle": "2024-08-30T03:24:47.668926Z",
     "shell.execute_reply": "2024-08-30T03:24:47.668149Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_polars(train)\n",
    "test_dataset = Dataset.from_polars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:47.672676Z",
     "iopub.status.busy": "2024-08-30T03:24:47.672018Z",
     "iopub.status.idle": "2024-08-30T03:24:51.411234Z",
     "shell.execute_reply": "2024-08-30T03:24:51.410466Z"
    }
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "config.attention_probs_dropout_prob = 0.0\n",
    "config.hidden_dropout_prob = 0.0\n",
    "config.num_labels = NUM_LABELS\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, config=config)\n",
    "tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "tokenizer.add_tokens([AddedToken(\" \" * 2, normalized=False)])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=NUM_LABELS\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:51.414718Z",
     "iopub.status.busy": "2024-08-30T03:24:51.414441Z",
     "iopub.status.idle": "2024-08-30T03:24:51.421384Z",
     "shell.execute_reply": "2024-08-30T03:24:51.420598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>label</th><th>Recommended IND</th><th>Positive Feedback Count</th><th>Division Name</th><th>Department Name</th><th>Class Name</th><th>fold</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f32</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lin…</td><td>4.0</td><td>1</td><td>4</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>2</td></tr><tr><td>1</td><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. wai…</td><td>4.0</td><td>1</td><td>0</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>2</td></tr><tr><td>2</td><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typ…</td><td>&quot;I love this skirt! i wasn&#x27;t su…</td><td>4.0</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>1</td></tr><tr><td>3</td><td>0</td><td>45</td><td>&quot;&quot;</td><td>&quot;I was really pleased with this…</td><td>4.0</td><td>1</td><td>9</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>0</td></tr><tr><td>4</td><td>0</td><td>57</td><td>&quot;Unique, pretty asymmetric skir…</td><td>&quot;I saw this skirt in retailer s…</td><td>4.0</td><td>1</td><td>1</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9995</td><td>232</td><td>57</td><td>&quot;Runs big on top&quot;</td><td>&quot;&quot;</td><td>2.0</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Dresses&quot;</td><td>&quot;Dresses&quot;</td><td>1</td></tr><tr><td>9996</td><td>232</td><td>58</td><td>&quot;&quot;</td><td>&quot;I loved the dress, but just no…</td><td>0.0</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Dresses&quot;</td><td>&quot;Dresses&quot;</td><td>0</td></tr><tr><td>9997</td><td>232</td><td>60</td><td>&quot;I was really disappointed&quot;</td><td>&quot;I was really hoping this dress…</td><td>1.0</td><td>0</td><td>7</td><td>&quot;General&quot;</td><td>&quot;Dresses&quot;</td><td>&quot;Dresses&quot;</td><td>1</td></tr><tr><td>9998</td><td>232</td><td>62</td><td>&quot;Too heavy&quot;</td><td>&quot;The design is beautiful but it…</td><td>1.0</td><td>0</td><td>0</td><td>&quot;General&quot;</td><td>&quot;Dresses&quot;</td><td>&quot;Dresses&quot;</td><td>1</td></tr><tr><td>9999</td><td>232</td><td>62</td><td>&quot;&quot;</td><td>&quot;I love this dress. very comfor…</td><td>4.0</td><td>1</td><td>2</td><td>&quot;General&quot;</td><td>&quot;Dresses&quot;</td><td>&quot;Dresses&quot;</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 12)\n",
       "┌───────┬─────────────┬─────┬─────────────────┬───┬──────────┬─────────────────┬────────────┬──────┐\n",
       "│ index ┆ Clothing ID ┆ Age ┆ Title           ┆ … ┆ Division ┆ Department Name ┆ Class Name ┆ fold │\n",
       "│ ---   ┆ ---         ┆ --- ┆ ---             ┆   ┆ Name     ┆ ---             ┆ ---        ┆ ---  │\n",
       "│ i64   ┆ i64         ┆ i64 ┆ str             ┆   ┆ ---      ┆ str             ┆ str        ┆ i64  │\n",
       "│       ┆             ┆     ┆                 ┆   ┆ str      ┆                 ┆            ┆      │\n",
       "╞═══════╪═════════════╪═════╪═════════════════╪═══╪══════════╪═════════════════╪════════════╪══════╡\n",
       "│ 0     ┆ 0           ┆ 25  ┆ 3-season skirt! ┆ … ┆ General  ┆ Bottoms         ┆ Skirts     ┆ 2    │\n",
       "│ 1     ┆ 0           ┆ 39  ┆ Very cute       ┆ … ┆ General  ┆ Bottoms         ┆ Skirts     ┆ 2    │\n",
       "│ 2     ┆ 0           ┆ 42  ┆ Beautiful!      ┆ … ┆ General  ┆ Bottoms         ┆ Skirts     ┆ 1    │\n",
       "│       ┆             ┆     ┆ fruns small for ┆   ┆          ┆                 ┆            ┆      │\n",
       "│       ┆             ┆     ┆ typ…            ┆   ┆          ┆                 ┆            ┆      │\n",
       "│ 3     ┆ 0           ┆ 45  ┆                 ┆ … ┆ General  ┆ Bottoms         ┆ Skirts     ┆ 0    │\n",
       "│ 4     ┆ 0           ┆ 57  ┆ Unique, pretty  ┆ … ┆ General  ┆ Bottoms         ┆ Skirts     ┆ 1    │\n",
       "│       ┆             ┆     ┆ asymmetric      ┆   ┆          ┆                 ┆            ┆      │\n",
       "│       ┆             ┆     ┆ skir…           ┆   ┆          ┆                 ┆            ┆      │\n",
       "│ …     ┆ …           ┆ …   ┆ …               ┆ … ┆ …        ┆ …               ┆ …          ┆ …    │\n",
       "│ 9995  ┆ 232         ┆ 57  ┆ Runs big on top ┆ … ┆ General  ┆ Dresses         ┆ Dresses    ┆ 1    │\n",
       "│ 9996  ┆ 232         ┆ 58  ┆                 ┆ … ┆ General  ┆ Dresses         ┆ Dresses    ┆ 0    │\n",
       "│ 9997  ┆ 232         ┆ 60  ┆ I was really    ┆ … ┆ General  ┆ Dresses         ┆ Dresses    ┆ 1    │\n",
       "│       ┆             ┆     ┆ disappointed    ┆   ┆          ┆                 ┆            ┆      │\n",
       "│ 9998  ┆ 232         ┆ 62  ┆ Too heavy       ┆ … ┆ General  ┆ Dresses         ┆ Dresses    ┆ 1    │\n",
       "│ 9999  ┆ 232         ┆ 62  ┆                 ┆ … ┆ General  ┆ Dresses         ┆ Dresses    ┆ 2    │\n",
       "└───────┴─────────────┴─────┴─────────────────┴───┴──────────┴─────────────────┴────────────┴──────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:51.424389Z",
     "iopub.status.busy": "2024-08-30T03:24:51.423781Z",
     "iopub.status.idle": "2024-08-30T03:24:57.773924Z",
     "shell.execute_reply": "2024-08-30T03:24:57.773075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b9625e09fb4625b362fc84f3b6c1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001eab575450470aae27ddafa16c864a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(examples, max_token_length: int):\n",
    "    separator = \" [SEP] \"\n",
    "\n",
    "    joined_text = examples[\"Title\"] + separator + examples[\"Review Text\"]\n",
    "\n",
    "    return tokenizer(\n",
    "        joined_text,\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "# def tokenize(examples, max_token_length: int):\n",
    "#     return tokenizer(\n",
    "#         examples[\"Title\"],\n",
    "#         max_length=max_token_length,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:57.777489Z",
     "iopub.status.busy": "2024-08-30T03:24:57.777187Z",
     "iopub.status.idle": "2024-08-30T03:24:57.786729Z",
     "shell.execute_reply": "2024-08-30T03:24:57.786069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Very cute[SEP] Love the asymmetrical hem. waist fit snugly as in perfectly. it ties in two spots with a hidden zipper as well. a little stiff in the fabric. classic colors but decided not to keep only because i didn't feel like we could wear it all year round.   can't petite or 0p was great (115 lbs)[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:57.789309Z",
     "iopub.status.busy": "2024-08-30T03:24:57.789039Z",
     "iopub.status.idle": "2024-08-30T03:24:57.797492Z",
     "shell.execute_reply": "2024-08-30T03:24:57.796962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] Runs small[SEP] Beautiful patterns and colors, but it sits very high and runs small. i'm normally a size 4 and got the small. zipped all the way, but on the snug side. the skirt sits so high that the fabric coming down was a bit awkward. such a shame because it really is beautiful and looks great on the model probably because she's wearing a belt to hide how high it rides and flares out.[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:24:57.800240Z",
     "iopub.status.busy": "2024-08-30T03:24:57.799984Z",
     "iopub.status.idle": "2024-08-30T03:25:03.514872Z",
     "shell.execute_reply": "2024-08-30T03:25:03.513884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bca622ed3994552aae6b3188606c927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf47af4a2624f8db402e023d7ec26ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_train = train_dataset.filter(\n",
    "    lambda x: x[\"fold\"] != USE_FOLD, num_proc=NUM_PROC\n",
    ")\n",
    "filtered_valid = train_dataset.filter(\n",
    "    lambda x: x[\"fold\"] == USE_FOLD, num_proc=NUM_PROC\n",
    ")\n",
    "\n",
    "train_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": filtered_train,\n",
    "        \"valid\": filtered_valid,\n",
    "    }\n",
    ")\n",
    "\n",
    "del filtered_train, filtered_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:25:03.518924Z",
     "iopub.status.busy": "2024-08-30T03:25:03.518540Z",
     "iopub.status.idle": "2024-08-30T03:25:03.523331Z",
     "shell.execute_reply": "2024-08-30T03:25:03.522405Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     preds_prob = softmax(predictions, axis=-1)\n",
    "#     return {\"eval_roc_auc\": roc_auc_score(labels, preds_prob[:, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-30T03:25:03.527706Z",
     "iopub.status.busy": "2024-08-30T03:25:03.526567Z",
     "iopub.status.idle": "2024-08-30T03:25:03.654183Z",
     "shell.execute_reply": "2024-08-30T03:25:03.652993Z"
    }
   },
   "outputs": [],
   "source": [
    "# スケジューラの設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_STEP,\n",
    "    eval_accumulation_steps=GRAD_ACC_STEP,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=2,\n",
    "    seed=SEED,\n",
    "    # metric_for_best_model=\"eval_roc_auc\",\n",
    "    # greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-08-30T03:25:03.659178Z",
     "iopub.status.busy": "2024-08-30T03:25:03.658605Z",
     "iopub.status.idle": "2024-08-30T03:25:55.740486Z",
     "shell.execute_reply": "2024-08-30T03:25:55.739151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/260 : < :, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 502.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAINING:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# モデルの学習\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# ログの保存に利用したストレージを削除\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# モデルの保存\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     trainer\u001b[38;5;241m.\u001b[39msave_model(MODEL_OUTPUT_PATH)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2330\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2328\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m-> 2330\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2334\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/optimizer.py:157\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_patched_step_method\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;66;03m# If the optimizer step was skipped, gradient overflow was detected.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:453\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    451\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 453\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 351\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/optimizer.py:212\u001b[0m, in \u001b[0;36mpatch_optimizer_step.<locals>.patched_step\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpatched_step\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    211\u001b[0m     accelerated_optimizer\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    178\u001b[0m         group,\n\u001b[1;32m    179\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m         state_steps,\n\u001b[1;32m    186\u001b[0m     )\n\u001b[0;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:609\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    607\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    612\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 502.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    # モデルの学習\n",
    "    trainer.train()\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    # os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    pass\n",
    "# else:\n",
    "#     # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         TRAINED_MODEL_PATH,\n",
    "#         num_labels=NUM_LABELS,\n",
    "#     )\n",
    "\n",
    "#     args = TrainingArguments(\n",
    "#         \".\",\n",
    "#         per_device_eval_batch_size=4,\n",
    "#         report_to=\"none\",\n",
    "#         fp16=True,\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         data_collator=data_collator,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>label</th><th>Recommended IND</th><th>Positive Feedback Count</th><th>fold</th></tr><tr><td>u32</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>f32</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lin…</td><td>4.0</td><td>1</td><td>4</td><td>2</td></tr><tr><td>1</td><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. wai…</td><td>4.0</td><td>1</td><td>0</td><td>2</td></tr><tr><td>2</td><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typ…</td><td>&quot;I love this skirt! i wasn&#x27;t su…</td><td>4.0</td><td>1</td><td>5</td><td>2</td></tr><tr><td>3</td><td>0</td><td>45</td><td>&quot;&quot;</td><td>&quot;I was really pleased with this…</td><td>4.0</td><td>1</td><td>9</td><td>2</td></tr><tr><td>4</td><td>0</td><td>57</td><td>&quot;Unique, pretty asymmetric skir…</td><td>&quot;I saw this skirt in retailer s…</td><td>4.0</td><td>1</td><td>1</td><td>2</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9995</td><td>232</td><td>57</td><td>&quot;Runs big on top&quot;</td><td>&quot;&quot;</td><td>2.0</td><td>1</td><td>5</td><td>2</td></tr><tr><td>9996</td><td>232</td><td>58</td><td>&quot;&quot;</td><td>&quot;I loved the dress, but just no…</td><td>0.0</td><td>1</td><td>5</td><td>2</td></tr><tr><td>9997</td><td>232</td><td>60</td><td>&quot;I was really disappointed&quot;</td><td>&quot;I was really hoping this dress…</td><td>1.0</td><td>0</td><td>7</td><td>2</td></tr><tr><td>9998</td><td>232</td><td>62</td><td>&quot;Too heavy&quot;</td><td>&quot;The design is beautiful but it…</td><td>1.0</td><td>0</td><td>0</td><td>2</td></tr><tr><td>9999</td><td>232</td><td>62</td><td>&quot;&quot;</td><td>&quot;I love this dress. very comfor…</td><td>4.0</td><td>1</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 9)\n",
       "┌───────┬─────────────┬─────┬──────────────────┬───┬───────┬─────────────┬──────────────────┬──────┐\n",
       "│ index ┆ Clothing ID ┆ Age ┆ Title            ┆ … ┆ label ┆ Recommended ┆ Positive         ┆ fold │\n",
       "│ ---   ┆ ---         ┆ --- ┆ ---              ┆   ┆ ---   ┆ IND         ┆ Feedback Count   ┆ ---  │\n",
       "│ u32   ┆ i64         ┆ i64 ┆ str              ┆   ┆ f32   ┆ ---         ┆ ---              ┆ i64  │\n",
       "│       ┆             ┆     ┆                  ┆   ┆       ┆ i64         ┆ i64              ┆      │\n",
       "╞═══════╪═════════════╪═════╪══════════════════╪═══╪═══════╪═════════════╪══════════════════╪══════╡\n",
       "│ 0     ┆ 0           ┆ 25  ┆ 3-season skirt!  ┆ … ┆ 4.0   ┆ 1           ┆ 4                ┆ 2    │\n",
       "│ 1     ┆ 0           ┆ 39  ┆ Very cute        ┆ … ┆ 4.0   ┆ 1           ┆ 0                ┆ 2    │\n",
       "│ 2     ┆ 0           ┆ 42  ┆ Beautiful! fruns ┆ … ┆ 4.0   ┆ 1           ┆ 5                ┆ 2    │\n",
       "│       ┆             ┆     ┆ small for typ…   ┆   ┆       ┆             ┆                  ┆      │\n",
       "│ 3     ┆ 0           ┆ 45  ┆                  ┆ … ┆ 4.0   ┆ 1           ┆ 9                ┆ 2    │\n",
       "│ 4     ┆ 0           ┆ 57  ┆ Unique, pretty   ┆ … ┆ 4.0   ┆ 1           ┆ 1                ┆ 2    │\n",
       "│       ┆             ┆     ┆ asymmetric skir… ┆   ┆       ┆             ┆                  ┆      │\n",
       "│ …     ┆ …           ┆ …   ┆ …                ┆ … ┆ …     ┆ …           ┆ …                ┆ …    │\n",
       "│ 9995  ┆ 232         ┆ 57  ┆ Runs big on top  ┆ … ┆ 2.0   ┆ 1           ┆ 5                ┆ 2    │\n",
       "│ 9996  ┆ 232         ┆ 58  ┆                  ┆ … ┆ 0.0   ┆ 1           ┆ 5                ┆ 2    │\n",
       "│ 9997  ┆ 232         ┆ 60  ┆ I was really     ┆ … ┆ 1.0   ┆ 0           ┆ 7                ┆ 2    │\n",
       "│       ┆             ┆     ┆ disappointed     ┆   ┆       ┆             ┆                  ┆      │\n",
       "│ 9998  ┆ 232         ┆ 62  ┆ Too heavy        ┆ … ┆ 1.0   ┆ 0           ┆ 0                ┆ 2    │\n",
       "│ 9999  ┆ 232         ┆ 62  ┆                  ┆ … ┆ 4.0   ┆ 1           ┆ 2                ┆ 2    │\n",
       "└───────┴─────────────┴─────┴──────────────────┴───┴───────┴─────────────┴──────────────────┴──────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     predictions, labels = eval_pred\n",
    "#     preds_prob = softmax(predictions, axis=-1)\n",
    "#     return {\"eval_roc_auc\": roc_auc_score(labels, preds_prob[:, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689ed85d482247ecb82d6ae725dc9f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936a7b3d018246d3bd290717bb2eb47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/4038 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b09473415f4964839c5e50554debe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4038 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "valid_dataset = train_dataset.filter(\n",
    "    lambda example: example[\"index\"] in train_valid_dataset[\"valid\"][\"index\"],\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "# valid_pred = softmax(trainer.predict(valid_dataset).predictions, axis=-1)\n",
    "valid_pred = trainer.predict(valid_dataset).predictions\n",
    "\n",
    "np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    valid_dataset.to_polars()\n",
    "    .select(pl.exclude(\"input_ids\", \"attention_mask\", \"token_type_ids\"))\n",
    "    .write_csv(f\"{MODEL_OUTPUT_PATH}/valid_dataset_{EXP_NAME}.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sisya_gonyuu(x, decimals=0):\n",
    "    return np.floor(x * 10**decimals + 0.5) / 10**decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = [num + 1.0 for num in valid_dataset[\"label\"]]\n",
    "pred_int_label = sisya_gonyuu(valid_pred + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 混同行列の作成\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 混同行列を作成\n",
    "cm = confusion_matrix(true_label, pred_int_label)\n",
    "\n",
    "# Seabornでヒートマップをプロット\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=[1, 2, 3, 4, 5],\n",
    "    yticklabels=[1, 2, 3, 4, 5],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.savefig(f\"{MODEL_OUTPUT_PATH}/confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768202080237742"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true_label, pred_int_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0,1,2,3,4の値を0~1に変換\n",
    "def normalize(array, min_value=0, max_value=4):\n",
    "    # 1~5の範囲にクリップ\n",
    "    clipped_array = np.clip(array, min_value, max_value)\n",
    "    # 0~1の範囲に正規化\n",
    "    return (clipped_array - min_value) / (max_value - min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.9622609898033627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cv_score = roc_auc_score(valid_dataset[\"Recommended IND\"], normalize(valid_pred))\n",
    "print(f\"CV Score: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストに対する計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5b5552043d4b698d99ddf1fe3c208b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "# test_pred = softmax(trainer.predict(test_dataset).predictions, axis=-1)\n",
    "test_pred = normalize(trainer.predict(test_dataset).predictions)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pl.read_csv(f\"{DATA_PATH}/sample_submission.csv\")\n",
    "\n",
    "if DEBUG:\n",
    "    sample_submission = sample_submission.head(100)\n",
    "\n",
    "(\n",
    "    sample_submission.with_columns(pl.Series(test_pred).alias(\"target\")).write_csv(\n",
    "        f\"{MODEL_OUTPUT_PATH}/submission_{EXP_NAME}_cv{cv_score:.4f}.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/usr/bin/aws': No such file or directory\n",
      "rm: cannot remove '/usr/bin/aws_completer': No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 58.0M  100 58.0M    0     0   156M      0 --:--:-- --:--:-- --:--:--  156M\n",
      "You can now run: /usr/local/bin/aws --version\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/config.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/config.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/added_tokens.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/added_tokens.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/special_tokens_map.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/special_tokens_map.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/scheduler.pt to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/scheduler.pt\n",
      "upload: ../trained_models/e008-predict-rating/added_tokens.json to s3://atmacup17/trained_model/e008-predict-rating/added_tokens.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/rng_state.pth to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/rng_state.pth\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/tokenizer_config.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/tokenizer_config.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/trainer_state.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/trainer_state.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/training_args.bin to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/training_args.bin\n",
      "upload: ../trained_models/e008-predict-rating/config.json to s3://atmacup17/trained_model/e008-predict-rating/config.json\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/spm.model to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/spm.model\n",
      "upload: ../trained_models/e008-predict-rating/confusion_matrix.png to s3://atmacup17/trained_model/e008-predict-rating/confusion_matrix.png\n",
      "upload: ../trained_models/e008-predict-rating/cv_score.txt to s3://atmacup17/trained_model/e008-predict-rating/cv_score.txt\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/tokenizer.json to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/tokenizer.json\n",
      "upload: ../trained_models/e008-predict-rating/special_tokens_map.json to s3://atmacup17/trained_model/e008-predict-rating/special_tokens_map.json\n",
      "upload: ../trained_models/e008-predict-rating/spm.model to s3://atmacup17/trained_model/e008-predict-rating/spm.model\n",
      "upload: ../trained_models/e008-predict-rating/submission_e008-predict-rating_cv0.7460.csv to s3://atmacup17/trained_model/e008-predict-rating/submission_e008-predict-rating_cv0.7460.csv\n",
      "upload: ../trained_models/e008-predict-rating/submission_e008-predict-rating_cv0.7540.csv to s3://atmacup17/trained_model/e008-predict-rating/submission_e008-predict-rating_cv0.7540.csv\n",
      "upload: ../trained_models/e008-predict-rating/submission_e008-predict-rating_cv0.9588.csv to s3://atmacup17/trained_model/e008-predict-rating/submission_e008-predict-rating_cv0.9588.csv\n",
      "upload: ../trained_models/e008-predict-rating/submission_e008-predict-rating_cv0.9623.csv to s3://atmacup17/trained_model/e008-predict-rating/submission_e008-predict-rating_cv0.9623.csv\n",
      "upload: ../trained_models/e008-predict-rating/tokenizer_config.json to s3://atmacup17/trained_model/e008-predict-rating/tokenizer_config.json\n",
      "upload: ../trained_models/e008-predict-rating/training_args.bin to s3://atmacup17/trained_model/e008-predict-rating/training_args.bin\n",
      "upload: ../trained_models/e008-predict-rating/valid_dataset.csv to s3://atmacup17/trained_model/e008-predict-rating/valid_dataset.csv\n",
      "upload: ../trained_models/e008-predict-rating/tokenizer.json to s3://atmacup17/trained_model/e008-predict-rating/tokenizer.json\n",
      "upload: ../trained_models/e008-predict-rating/valid_dataset_e008-predict-rating.csv to s3://atmacup17/trained_model/e008-predict-rating/valid_dataset_e008-predict-rating.csv\n",
      "upload: ../trained_models/e008-predict-rating/valid_prediction.npy to s3://atmacup17/trained_model/e008-predict-rating/valid_prediction.npy\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/model.safetensors to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/model.safetensors\n",
      "upload: ../trained_models/e008-predict-rating/model.safetensors to s3://atmacup17/trained_model/e008-predict-rating/model.safetensors\n",
      "upload: ../trained_models/e008-predict-rating/checkpoint-133/optimizer.pt to s3://atmacup17/trained_model/e008-predict-rating/checkpoint-133/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "# S3へのアップロード\n",
    "# if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "if UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://{COMPETITION_NAME}/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5306b07f03ed40148e627ff22383efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▆▁▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆██▁▆▂▆▄▆</td></tr><tr><td>eval/samples_per_second</td><td>▃▁▁█▃▇▃▅▃</td></tr><tr><td>eval/steps_per_second</td><td>▃▁▁█▃▇▃▅▃</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁█</td></tr><tr><td>test/samples_per_second</td><td>█▁</td></tr><tr><td>test/steps_per_second</td><td>█▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▅▅█▅▁▄▂▁▅▂▃▃▂▃▂▁▂▁▁▁▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇██████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>██▆▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.43973</td></tr><tr><td>eval/runtime</td><td>17.9351</td></tr><tr><td>eval/samples_per_second</td><td>225.145</td></tr><tr><td>eval/steps_per_second</td><td>28.157</td></tr><tr><td>test/loss</td><td>0.41285</td></tr><tr><td>test/runtime</td><td>48.9621</td></tr><tr><td>test/samples_per_second</td><td>227.829</td></tr><tr><td>test/steps_per_second</td><td>28.491</td></tr><tr><td>total_flos</td><td>1550276519995392.0</td></tr><tr><td>train/epoch</td><td>3.94638</td></tr><tr><td>train/global_step</td><td>184</td></tr><tr><td>train/grad_norm</td><td>1.88619</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3612</td></tr><tr><td>train_loss</td><td>1.14957</td></tr><tr><td>train_runtime</td><td>567.0517</td></tr><tr><td>train_samples_per_second</td><td>42.056</td></tr><tr><td>train_steps_per_second</td><td>0.324</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">e008-predict-rating</strong> at: <a href='https://wandb.ai/sinchir0/atmacup17/runs/mb3vxww4' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17/runs/mb3vxww4</a><br/> View project at: <a href='https://wandb.ai/sinchir0/atmacup17' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240829_144623-mb3vxww4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "autoscroll": "auto",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
