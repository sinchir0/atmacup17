{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目的\n",
    "debertaでの学習を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path setting\n",
    "EXP_NAME = \"e003-add-rec-fold\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-xsmall\"\n",
    "COMPETITION_NAME = \"atmacup17\"\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "ENV_PATH = \"env_file\"\n",
    "DATASET_NAME = f\"{EXP_NAME}-{MODEL_NAME.split('/')[-1]}\"\n",
    "MODEL_OUTPUT_PATH = f\"trained_models/{EXP_NAME}\"\n",
    "TARGET_COL = \"Recommended IND\"\n",
    "\n",
    "# experiment parameter\n",
    "DEBUG = False\n",
    "TRAINING = True\n",
    "UPLOAD_DATA_TO_S3 = True\n",
    "# UPLOAD_DATA_TO_KAGGLE = True\n",
    "WANDB = True\n",
    "\n",
    "# model parameter\n",
    "TRAINING_MAX_LENGTH = 512\n",
    "INFERENCE_MAX_LENGTH = 512\n",
    "SEED = 42\n",
    "VALID_DATA_SIZE = 0.3\n",
    "EPOCH = 4\n",
    "LR = 2e-04\n",
    "TRAIN_BS = 8\n",
    "GRAD_ACC_STEP = 128 // TRAIN_BS  # 仮想的なバッチサイズはTRAIN_BS * GRAD_ACC_STEPとなる\n",
    "EVAL_BS = 8\n",
    "NUM_LABELS = 2\n",
    "\n",
    "USE_FOLD = 0  # Fold数は3(0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 29 12:33:19 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0             43W /  300W |    2163MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     37767      C   /opt/conda/bin/python                        2160MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shinichiro.saito/atmacup17/exp\n",
      "GCP!\n",
      "/home/shinichiro.saito/atmacup17/data\n",
      "/home/shinichiro.saito/atmacup17/exp\n",
      "GCP!\n",
      "/home/shinichiro.saito/atmacup17/trained_models/e003-add-rec-fold\n",
      "/home/shinichiro.saito/atmacup17/exp\n",
      "GCP!\n"
     ]
    }
   ],
   "source": [
    "def resolve_path(base_path: str) -> str:\n",
    "    import os\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    if cwd == f\"/notebooks\":\n",
    "        print(\"Jupyter Kernel By VSCode!\")\n",
    "        return \"kernel\", f\"/notebooks/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}\":\n",
    "        print(\"nohup!\")\n",
    "        return base_path\n",
    "    elif cwd == f\"/notebooks/{COMPETITION_NAME}/{COMPETITION_NAME}/exp\":\n",
    "        print(\"Jupyter Lab!\")\n",
    "        return \"nohup\", f\"../../{base_path}\"\n",
    "    elif cwd == f\"/content\":\n",
    "        print(\"Google Colab!\")\n",
    "        return \"colab\", f\"/content/drive/MyDrive/Kaggle/{COMPETITION_NAME}/{base_path}\"\n",
    "    elif cwd.startswith(\"/home/shinichiro.saito\"):\n",
    "        print(\"GCP!\")\n",
    "        return \"GCP\", f\"/home/shinichiro.saito/{COMPETITION_NAME}/{base_path}\"\n",
    "    else:\n",
    "        raise Exception(\"Unknown environment\")\n",
    "\n",
    "\n",
    "ENV_NAME, DATA_PATH = resolve_path(DATA_PATH)\n",
    "print(DATA_PATH)\n",
    "_, MODEL_OUTPUT_PATH = resolve_path(MODEL_OUTPUT_PATH)\n",
    "print(MODEL_OUTPUT_PATH)\n",
    "_, ENV_PATH = resolve_path(ENV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset_name(dataset_name: str) -> None:\n",
    "    if len(dataset_name) < 6 or len(dataset_name) > 50:\n",
    "        raise Exception(\n",
    "            f\"データセットの文字列は6~50文字にしてください。現在{len(DATASET_NAME)}文字\"\n",
    "        )\n",
    "    if \"_\" in dataset_name:\n",
    "        raise Exception(\"datasetの名称に_の使用は禁止です\")\n",
    "\n",
    "\n",
    "validate_dataset_name(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENV_NAME != \"GCP\":\n",
    "    %pip install -qq polars==1.0.0\n",
    "    %pip install -qq transformers==4.42.3\n",
    "    %pip install -qq sentencepiece==0.2.0\n",
    "    %pip install -qq datasets==2.20.0\n",
    "    %pip install -qq evaluate==0.4.2\n",
    "    %pip install -qq seqeval==1.2.2\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq python-dotenv==1.0.1\n",
    "    %pip install -qq wandb==0.17.4\n",
    "    %pip install -qq bitsandbytes==0.43.1\n",
    "    %pip install -qq accelerate==0.32.0\n",
    "    %pip install -qq peft==0.11.1\n",
    "\n",
    "    # formatter\n",
    "    %pip install -qq black isort\n",
    "\n",
    "    %pip install -qq kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import ast\n",
    "import json\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "import wandb\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    DatasetDict,\n",
    "    Value,\n",
    "    concatenate_datasets,\n",
    "    load_dataset,\n",
    "    ClassLabel,\n",
    ")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tokenizers import AddedToken\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    DebertaV2PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.deberta_v2.modeling_deberta_v2 import (\n",
    "    ContextPooler,\n",
    "    StableDropout,\n",
    "    DebertaV2Model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "NUM_PROC = os.cpu_count()\n",
    "NUM_PROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import evaluate\n",
    "\n",
    "assert transformers.__version__ == \"4.42.3\"\n",
    "assert datasets.__version__ == \"2.20.0\"\n",
    "assert evaluate.__version__ == \"0.4.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed the same seed to all\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(f\"{ENV_PATH}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msinchir0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/shinichiro.saito/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/shinichiro.saito/atmacup17/exp/wandb/run-20240829_123328-dxyqugod</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sinchir0/atmacup17/runs/dxyqugod' target=\"_blank\">e003-add-rec-fold</a></strong> to <a href='https://wandb.ai/sinchir0/atmacup17' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sinchir0/atmacup17' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sinchir0/atmacup17/runs/dxyqugod' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17/runs/dxyqugod</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'wandb'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.login(key=os.environ[\"WANDB_API_KEY\"])\n",
    "    wandb.init(project=COMPETITION_NAME, name=EXP_NAME)\n",
    "    REPORT_TO = \"wandb\"\n",
    "else:\n",
    "    REPORT_TO = \"none\"\n",
    "\n",
    "REPORT_TO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import & Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_PATH}/rec_stratified_fold.json\") as f:\n",
    "    label_stratified_fold = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (\n",
    "    pl.read_csv(f\"{DATA_PATH}/train.csv\")\n",
    "    .with_columns(\n",
    "        pl.col(\"Title\").fill_null(\"\"),\n",
    "    )\n",
    "    .rename({TARGET_COL: \"label\"})\n",
    "    .with_columns(  # foldを追加する\n",
    "        pl.col(\"Clothing ID\").replace(label_stratified_fold).alias(\"fold\")\n",
    "    )\n",
    ")\n",
    "\n",
    "test = pl.read_csv(f\"{DATA_PATH}/test.csv\").with_columns(\n",
    "    pl.col(\"Title\").fill_null(\"\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.head(100)\n",
    "    test = test.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_polars(train)\n",
    "test_dataset = Dataset.from_polars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens([AddedToken(\"\\n\", normalized=False)])\n",
    "tokenizer.add_tokens([AddedToken(\" \" * 2, normalized=False)])\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=NUM_LABELS\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>Rating</th><th>label</th><th>Positive Feedback Count</th><th>fold</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lin…</td><td>5</td><td>1</td><td>4</td><td>0</td></tr><tr><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. wai…</td><td>5</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typ…</td><td>&quot;I love this skirt! i wasn&#x27;t su…</td><td>5</td><td>1</td><td>5</td><td>0</td></tr><tr><td>0</td><td>45</td><td>&quot;&quot;</td><td>&quot;I was really pleased with this…</td><td>5</td><td>1</td><td>9</td><td>0</td></tr><tr><td>0</td><td>57</td><td>&quot;Unique, pretty asymmetric skir…</td><td>&quot;I saw this skirt in retailer s…</td><td>5</td><td>1</td><td>1</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>232</td><td>57</td><td>&quot;Runs big on top&quot;</td><td>null</td><td>3</td><td>1</td><td>5</td><td>2</td></tr><tr><td>232</td><td>58</td><td>&quot;&quot;</td><td>&quot;I loved the dress, but just no…</td><td>1</td><td>1</td><td>5</td><td>2</td></tr><tr><td>232</td><td>60</td><td>&quot;I was really disappointed&quot;</td><td>&quot;I was really hoping this dress…</td><td>2</td><td>0</td><td>7</td><td>2</td></tr><tr><td>232</td><td>62</td><td>&quot;Too heavy&quot;</td><td>&quot;The design is beautiful but it…</td><td>2</td><td>0</td><td>0</td><td>2</td></tr><tr><td>232</td><td>62</td><td>&quot;&quot;</td><td>&quot;I love this dress. very comfor…</td><td>5</td><td>1</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 8)\n",
       "┌─────────────┬─────┬──────────────────┬─────────────────┬────────┬───────┬─────────────────┬──────┐\n",
       "│ Clothing ID ┆ Age ┆ Title            ┆ Review Text     ┆ Rating ┆ label ┆ Positive        ┆ fold │\n",
       "│ ---         ┆ --- ┆ ---              ┆ ---             ┆ ---    ┆ ---   ┆ Feedback Count  ┆ ---  │\n",
       "│ i64         ┆ i64 ┆ str              ┆ str             ┆ i64    ┆ i64   ┆ ---             ┆ i64  │\n",
       "│             ┆     ┆                  ┆                 ┆        ┆       ┆ i64             ┆      │\n",
       "╞═════════════╪═════╪══════════════════╪═════════════════╪════════╪═══════╪═════════════════╪══════╡\n",
       "│ 0           ┆ 25  ┆ 3-season skirt!  ┆ Adorable,       ┆ 5      ┆ 1     ┆ 4               ┆ 0    │\n",
       "│             ┆     ┆                  ┆ well-made       ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ skirt! lin…     ┆        ┆       ┆                 ┆      │\n",
       "│ 0           ┆ 39  ┆ Very cute        ┆ Love the        ┆ 5      ┆ 1     ┆ 0               ┆ 0    │\n",
       "│             ┆     ┆                  ┆ asymmetrical    ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ hem. wai…       ┆        ┆       ┆                 ┆      │\n",
       "│ 0           ┆ 42  ┆ Beautiful! fruns ┆ I love this     ┆ 5      ┆ 1     ┆ 5               ┆ 0    │\n",
       "│             ┆     ┆ small for typ…   ┆ skirt! i wasn't ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ su…             ┆        ┆       ┆                 ┆      │\n",
       "│ 0           ┆ 45  ┆                  ┆ I was really    ┆ 5      ┆ 1     ┆ 9               ┆ 0    │\n",
       "│             ┆     ┆                  ┆ pleased with    ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ this…           ┆        ┆       ┆                 ┆      │\n",
       "│ 0           ┆ 57  ┆ Unique, pretty   ┆ I saw this      ┆ 5      ┆ 1     ┆ 1               ┆ 0    │\n",
       "│             ┆     ┆ asymmetric skir… ┆ skirt in        ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ retailer s…     ┆        ┆       ┆                 ┆      │\n",
       "│ …           ┆ …   ┆ …                ┆ …               ┆ …      ┆ …     ┆ …               ┆ …    │\n",
       "│ 232         ┆ 57  ┆ Runs big on top  ┆ null            ┆ 3      ┆ 1     ┆ 5               ┆ 2    │\n",
       "│ 232         ┆ 58  ┆                  ┆ I loved the     ┆ 1      ┆ 1     ┆ 5               ┆ 2    │\n",
       "│             ┆     ┆                  ┆ dress, but just ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ no…             ┆        ┆       ┆                 ┆      │\n",
       "│ 232         ┆ 60  ┆ I was really     ┆ I was really    ┆ 2      ┆ 0     ┆ 7               ┆ 2    │\n",
       "│             ┆     ┆ disappointed     ┆ hoping this     ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ dress…          ┆        ┆       ┆                 ┆      │\n",
       "│ 232         ┆ 62  ┆ Too heavy        ┆ The design is   ┆ 2      ┆ 0     ┆ 0               ┆ 2    │\n",
       "│             ┆     ┆                  ┆ beautiful but   ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ it…             ┆        ┆       ┆                 ┆      │\n",
       "│ 232         ┆ 62  ┆                  ┆ I love this     ┆ 5      ┆ 1     ┆ 2               ┆ 2    │\n",
       "│             ┆     ┆                  ┆ dress. very     ┆        ┆       ┆                 ┆      │\n",
       "│             ┆     ┆                  ┆ comfor…         ┆        ┆       ┆                 ┆      │\n",
       "└─────────────┴─────┴──────────────────┴─────────────────┴────────┴───────┴─────────────────┴──────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850a6c36a9484f649746d45d83b8a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea84553135294ca9b084239f79a9e30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def tokenize(examples, max_token_length: int):\n",
    "#     separator = \" [SEP] \"\n",
    "\n",
    "#     joined_text = (\n",
    "#         examples[\"last_prompt\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_a\"]\n",
    "#         + separator\n",
    "#         + examples[\"last_response_b\"]\n",
    "#     )\n",
    "\n",
    "#     return tokenizer(\n",
    "#         joined_text,\n",
    "#         max_length=max_token_length,\n",
    "#         truncation=True,\n",
    "#         padding=\"max_length\",\n",
    "#     )\n",
    "\n",
    "\n",
    "def tokenize(examples, max_token_length: int):\n",
    "    return tokenizer(\n",
    "        examples[\"Title\"],\n",
    "        max_length=max_token_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": TRAINING_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Very cute[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_dataset[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Runs small[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(test_dataset[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ac5c8d028540ef90dbd3c51eb81d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c143ea1b4f840f692affb4dfc646fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_train = train_dataset.filter(\n",
    "    lambda x: x[\"fold\"] != USE_FOLD, num_proc=NUM_PROC\n",
    ")\n",
    "filtered_valid = train_dataset.filter(\n",
    "    lambda x: x[\"fold\"] == USE_FOLD, num_proc=NUM_PROC\n",
    ")\n",
    "\n",
    "train_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": filtered_train,\n",
    "        \"valid\": filtered_valid,\n",
    "    }\n",
    ")\n",
    "\n",
    "del filtered_train, filtered_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds_prob = softmax(predictions, axis=-1)\n",
    "    return {\"eval_roc_auc\": roc_auc_score(labels, preds_prob[:, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケジューラの設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_PATH,\n",
    "    learning_rate=LR,\n",
    "    per_device_train_batch_size=TRAIN_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACC_STEP,\n",
    "    eval_accumulation_steps=GRAD_ACC_STEP,\n",
    "    per_device_eval_batch_size=EVAL_BS,\n",
    "    num_train_epochs=EPOCH,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.1,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=2,\n",
    "    seed=SEED,\n",
    "    metric_for_best_model=\"eval_roc_auc\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    report_to=REPORT_TO,\n",
    "    run_name=EXP_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    fp16_full_eval=True,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_valid_dataset[\"train\"],\n",
    "    eval_dataset=train_valid_dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [188/188 09:42, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.440724</td>\n",
       "      <td>0.787819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.373900</td>\n",
       "      <td>0.320036</td>\n",
       "      <td>0.885151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.343100</td>\n",
       "      <td>0.329140</td>\n",
       "      <td>0.874420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.301872</td>\n",
       "      <td>0.895191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>0.283219</td>\n",
       "      <td>0.902057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.222000</td>\n",
       "      <td>0.306229</td>\n",
       "      <td>0.901602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.318747</td>\n",
       "      <td>0.898413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.316603</td>\n",
       "      <td>0.889722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.300405</td>\n",
       "      <td>0.906201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if TRAINING:\n",
    "    # モデルの学習\n",
    "    trainer.train()\n",
    "    # ログの保存に利用したストレージを削除\n",
    "    # os.system(f\"rm -rf {MODEL_OUTPUT_PATH}/checkpoint-*\")\n",
    "    # モデルの保存\n",
    "    trainer.save_model(MODEL_OUTPUT_PATH)\n",
    "else:\n",
    "    pass\n",
    "# else:\n",
    "#     # TRAINED_MODEL_PATHを用いて、学習済のモデルを読み込む\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#         TRAINED_MODEL_PATH,\n",
    "#         num_labels=NUM_LABELS,\n",
    "#     )\n",
    "\n",
    "#     args = TrainingArguments(\n",
    "#         \".\",\n",
    "#         per_device_eval_batch_size=4,\n",
    "#         report_to=\"none\",\n",
    "#         fp16=True,\n",
    "#     )\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=args,\n",
    "#         data_collator=data_collator,\n",
    "#         tokenizer=tokenizer,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# valid_datasetの作成・保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds_prob = softmax(predictions, axis=-1)\n",
    "    return {\"eval_roc_auc\": roc_auc_score(labels, preds_prob[:, 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533ea42b6d99490bb64d6c2c8ff1a8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfaf97994dac4a4da51278fb72cb1a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/3911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f4266e752f46c584e0a7b37a197bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAININGをINFERRENCEでMAX_TOKENを変えるために、validを作り直す\n",
    "valid_dataset = train_dataset.filter(\n",
    "    lambda example: example[\"Clothing ID\"]\n",
    "    in train_valid_dataset[\"valid\"][\"Clothing ID\"],\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "valid_pred = softmax(trainer.predict(valid_dataset).predictions, axis=-1)\n",
    "\n",
    "np.save(f\"{MODEL_OUTPUT_PATH}/valid_prediction.npy\", valid_pred)\n",
    "\n",
    "valid_dataset = valid_dataset.map(\n",
    "    add_valid_pred, with_indices=True, fn_kwargs={\"valid_pred\": valid_pred[:, 1]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    valid_dataset.to_polars()\n",
    "    .select(pl.exclude(\"input_ids\", \"attention_mask\", \"token_type_ids\"))\n",
    "    .write_csv(f\"{MODEL_OUTPUT_PATH}/valid_dataset.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 混同行列の作成\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 混同行列を作成\n",
    "cm = confusion_matrix(valid_dataset[\"label\"], valid_pred.argmax(axis=1))\n",
    "\n",
    "# Seabornでヒートマップをプロット\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=[0, 1],\n",
    "    yticklabels=[0, 1],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.savefig(f\"{MODEL_OUTPUT_PATH}/confusion_matrix.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785476860138072"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(valid_dataset[\"label\"], valid_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 0.906294589327529\n"
     ]
    }
   ],
   "source": [
    "cv_score = roc_auc_score(valid_dataset[\"label\"], valid_pred[:, 1])\n",
    "print(f\"CV Score: {cv_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_textを保存\n",
    "with open(f\"{MODEL_OUTPUT_PATH}/cv_score.txt\", \"w\") as f:\n",
    "    f.write(str(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# テストに対する計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting TOKENIZERS_PARALLELISM=false for forked processes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b54c21cd6e4a8f8094fd23238dc297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = test_dataset.map(\n",
    "    tokenize,\n",
    "    batched=False,\n",
    "    fn_kwargs={\"max_token_length\": INFERENCE_MAX_LENGTH},\n",
    "    num_proc=NUM_PROC,\n",
    ")\n",
    "\n",
    "\n",
    "def add_valid_pred(example, idx, valid_pred):\n",
    "    example[\"valid_pred\"] = valid_pred[idx]\n",
    "    return example\n",
    "\n",
    "\n",
    "test_pred = softmax(trainer.predict(test_dataset).predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提出ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pl.read_csv(f\"{DATA_PATH}/sample_submission.csv\")\n",
    "\n",
    "if DEBUG:\n",
    "    sample_submission = sample_submission.head(100)\n",
    "\n",
    "(\n",
    "    sample_submission.with_columns(\n",
    "        pl.Series(test_pred[:, 1]).alias(\"target\")\n",
    "    ).write_csv(f\"{MODEL_OUTPUT_PATH}/submission_{EXP_NAME}_cv{cv_score:.4f}.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWSへのアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/usr/bin/aws': No such file or directory\n",
      "rm: cannot remove '/usr/bin/aws_completer': No such file or directory\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 58.0M  100 58.0M    0     0   157M      0 --:--:-- --:--:-- --:--:--  157M\n",
      "You can now run: /usr/local/bin/aws --version\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/added_tokens.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/added_tokens.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/config.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/config.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/scheduler.pt to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/scheduler.pt\n",
      "upload: ../trained_models/e003-add-rec-fold/added_tokens.json to s3://atmacup17/trained_model/e003-add-rec-fold/added_tokens.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/rng_state.pth to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/rng_state.pth\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/special_tokens_map.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/special_tokens_map.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/tokenizer_config.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/tokenizer_config.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/trainer_state.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/trainer_state.json\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/training_args.bin to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/training_args.bin\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/spm.model to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/spm.model\n",
      "upload: ../trained_models/e003-add-rec-fold/config.json to s3://atmacup17/trained_model/e003-add-rec-fold/config.json\n",
      "upload: ../trained_models/e003-add-rec-fold/confusion_matrix.png to s3://atmacup17/trained_model/e003-add-rec-fold/confusion_matrix.png\n",
      "upload: ../trained_models/e003-add-rec-fold/cv_score.txt to s3://atmacup17/trained_model/e003-add-rec-fold/cv_score.txt\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/tokenizer.json to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/tokenizer.json\n",
      "upload: ../trained_models/e003-add-rec-fold/special_tokens_map.json to s3://atmacup17/trained_model/e003-add-rec-fold/special_tokens_map.json\n",
      "upload: ../trained_models/e003-add-rec-fold/spm.model to s3://atmacup17/trained_model/e003-add-rec-fold/spm.model\n",
      "upload: ../trained_models/e003-add-rec-fold/submission_e003-add-rec-fold_cv0.9063.csv to s3://atmacup17/trained_model/e003-add-rec-fold/submission_e003-add-rec-fold_cv0.9063.csv\n",
      "upload: ../trained_models/e003-add-rec-fold/tokenizer_config.json to s3://atmacup17/trained_model/e003-add-rec-fold/tokenizer_config.json\n",
      "upload: ../trained_models/e003-add-rec-fold/training_args.bin to s3://atmacup17/trained_model/e003-add-rec-fold/training_args.bin\n",
      "upload: ../trained_models/e003-add-rec-fold/valid_dataset.csv to s3://atmacup17/trained_model/e003-add-rec-fold/valid_dataset.csv\n",
      "upload: ../trained_models/e003-add-rec-fold/tokenizer.json to s3://atmacup17/trained_model/e003-add-rec-fold/tokenizer.json\n",
      "upload: ../trained_models/e003-add-rec-fold/valid_prediction.npy to s3://atmacup17/trained_model/e003-add-rec-fold/valid_prediction.npy\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/model.safetensors to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/model.safetensors\n",
      "upload: ../trained_models/e003-add-rec-fold/model.safetensors to s3://atmacup17/trained_model/e003-add-rec-fold/model.safetensors\n",
      "upload: ../trained_models/e003-add-rec-fold/checkpoint-171/optimizer.pt to s3://atmacup17/trained_model/e003-add-rec-fold/checkpoint-171/optimizer.pt\n"
     ]
    }
   ],
   "source": [
    "# S3へのアップロード\n",
    "# if not DEBUG and UPLOAD_DATA_TO_S3:\n",
    "if UPLOAD_DATA_TO_S3:\n",
    "    # uninstall\n",
    "    !sudo rm /usr/bin/aws\n",
    "    !sudo rm /usr/bin/aws_completer\n",
    "    !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "    # install\n",
    "    !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "    !unzip -o -qq awscliv2.zip\n",
    "    !sudo ./aws/install --update\n",
    "\n",
    "    # upload\n",
    "    output_name = MODEL_OUTPUT_PATH.split(\"/\")[-1]\n",
    "    os.system(\n",
    "        f\"aws s3 cp --recursive {MODEL_OUTPUT_PATH} s3://{COMPETITION_NAME}/trained_model/{output_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード（参考）\n",
    "# !sudo rm /usr/bin/aws\n",
    "# !sudo rm /usr/bin/aws_completer\n",
    "# !sudo rm -rf /usr/local/aws-cli\n",
    "\n",
    "# !curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "# !unzip -o -qq awscliv2.zip\n",
    "# !sudo ./aws/install --update\n",
    "\n",
    "# !aws s3 cp --recursive s3://automated-essay-scoring/trained_model/e005-regression /notebooks/automated_essay_scoring/trained_models/e005-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7299000dff274aafaac3cb6620f5758c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▃▂▁▂▃▂▂</td></tr><tr><td>eval/roc_auc</td><td>▁▇▆▇███▇█</td></tr><tr><td>eval/runtime</td><td>▆▆▅▄▄█▅▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▃▃▃▄▅▁▄█▅</td></tr><tr><td>eval/steps_per_second</td><td>▃▃▃▄▅▁▄█▅</td></tr><tr><td>test/eval_roc_auc</td><td>▁▁</td></tr><tr><td>test/loss</td><td>▁▁</td></tr><tr><td>test/runtime</td><td>▁▁█</td></tr><tr><td>test/samples_per_second</td><td>▁▃█</td></tr><tr><td>test/steps_per_second</td><td>▁▃█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▅▄▂▂▁▂▇▄▄▅▄█▄▂▂▂▁▂▂▄▃▄▃▅▂▁▂▁▅▃▂▂▃▄▂▂▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▇███████▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▅▅▄▃▃▄▄▃▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▃▂▂▂▁▃▃▂▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.3004</td></tr><tr><td>eval/roc_auc</td><td>0.9062</td></tr><tr><td>eval/runtime</td><td>17.9556</td></tr><tr><td>eval/samples_per_second</td><td>217.815</td></tr><tr><td>eval/steps_per_second</td><td>27.234</td></tr><tr><td>test/eval_roc_auc</td><td>0.90629</td></tr><tr><td>test/loss</td><td>0.30039</td></tr><tr><td>test/runtime</td><td>48.3848</td></tr><tr><td>test/samples_per_second</td><td>230.547</td></tr><tr><td>test/steps_per_second</td><td>28.831</td></tr><tr><td>total_flos</td><td>1583834774636544.0</td></tr><tr><td>train/epoch</td><td>3.94751</td></tr><tr><td>train/global_step</td><td>188</td></tr><tr><td>train/grad_norm</td><td>0.97634</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2056</td></tr><tr><td>train_loss</td><td>0.30431</td></tr><tr><td>train_runtime</td><td>585.2411</td></tr><tr><td>train_samples_per_second</td><td>41.617</td></tr><tr><td>train_steps_per_second</td><td>0.321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">e003-add-rec-fold</strong> at: <a href='https://wandb.ai/sinchir0/atmacup17/runs/dxyqugod' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17/runs/dxyqugod</a><br/> View project at: <a href='https://wandb.ai/sinchir0/atmacup17' target=\"_blank\">https://wandb.ai/sinchir0/atmacup17</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240829_123328-dxyqugod/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"finish Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
